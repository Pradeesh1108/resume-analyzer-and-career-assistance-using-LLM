{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T16:53:05.550989Z",
     "start_time": "2024-11-16T16:53:05.536859Z"
    }
   },
   "source": [
    "import PyPDF2\n",
    "import docx2txt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pradeesh11/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pradeesh11/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:53:08.690363Z",
     "start_time": "2024-11-16T16:53:08.681229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_file = open(file_path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page in range(len(pdf_reader.pages)):\n",
    "        page_obj = pdf_reader.pages[page]\n",
    "        text += page_obj.extract_text()\n",
    "    pdf_file.close()\n",
    "    return text"
   ],
   "id": "74cdbff37d480ebe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:53:10.876552Z",
     "start_time": "2024-11-16T16:53:10.871116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_docx(file_path):\n",
    "    text = docx2txt.process(file_path)\n",
    "    return text"
   ],
   "id": "460b5e370c1d4c88",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:53:15.534506Z",
     "start_time": "2024-11-16T16:53:15.520864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in word_tokens if word.isalpha() and word not in stop_words]\n",
    "    return filtered_tokens"
   ],
   "id": "78b465f3effcf573",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:53:31.112614Z",
     "start_time": "2024-11-16T16:53:18.274974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(resume_text, jd_text):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([resume_text, jd_text])\n",
    "    similarity_score = cosine_similarity(vectors)[0][1]\n",
    "    return similarity_score"
   ],
   "id": "5126e46dbba991a8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def main():\n",
    "    resume_file_path = \"Dataset/TESTINGFILE1.pdf\"\n",
    "    jd_file_path = \"Dataset/TESTINGFILE2.pdf\"\n",
    "\n",
    "    if resume_file_path.endswith('.pdf'):\n",
    "        resume_text = extract_text_from_pdf(resume_file_path) #pdf\n",
    "        jd_text = extract_text_from_pdf(jd_file_path)\n",
    "    elif resume_file_path.endswith('.docx'):\n",
    "        resume_text = extract_text_from_docx(resume_file_path) #docx\n",
    "        jd_text = extract_text_from_pdf(jd_file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file format.\")\n",
    "        return\n",
    "    \n",
    "    preprocessed_resume_text = preprocess_text(resume_text)\n",
    "    preprocessed_jd_text = preprocess_text(jd_text)\n",
    "\n",
    "    similarity_score = calculate_similarity(' '.join(preprocessed_resume_text), ' '.join(preprocessed_jd_text))\n",
    "    print(\"The similarity score between the resume and job description is: \", similarity_score)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "c40e712f5fb22ade"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:54:38.435378Z",
     "start_time": "2024-11-16T16:54:38.378195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    resume_file_path = \"PradeeshResume.pdf\"\n",
    "\n",
    "    # Provide the job description as plain text\n",
    "    jd_text = \"\"\"Amazon is at the forefront of innovative technology, driving progress in AI and machine learning solutions. Our mission is to leverage advanced data science and engineering to deliver impactful and scalable products for our clients. We are looking for a passionate Machine Learning Engineer to join our dynamic team and contribute to cutting-edge projects.\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "Design, develop, and deploy scalable machine learning models and algorithms for a variety of applications.\n",
    "Collaborate with cross-functional teams, including data scientists, software engineers, and product managers, to gather requirements and implement solutions.\n",
    "Preprocess and analyze large datasets, ensuring data quality and feature engineering for optimal model performance.\n",
    "Build and maintain machine learning pipelines for training, evaluation, and deployment.\n",
    "Optimize and fine-tune models for performance, scalability, and accuracy using techniques such as hyperparameter tuning and model compression.\n",
    "Conduct thorough testing and validation of models to ensure reliability and robustness in production.\n",
    "Monitor and maintain deployed models, implementing strategies for model retraining and performance tracking.\n",
    "Stay current with the latest advancements in machine learning and AI, applying innovative techniques and technologies as appropriate.\n",
    "Document processes, model architectures, and code to ensure maintainability and knowledge sharing within the team.\n",
    "Qualifications:\n",
    "\n",
    "Bachelor's or Master's degree in Computer Science, AI/ML, Data Science, or a related field.\n",
    "Strong proficiency in Python and experience with libraries/frameworks such as TensorFlow, PyTorch, or Scikit-Learn.\n",
    "Solid understanding of machine learning algorithms, neural networks, and deep learning architectures.\n",
    "Experience with data preprocessing and feature engineering.\n",
    "Hands-on experience with cloud platforms (AWS, GCP, or Azure) for deploying machine learning models.\n",
    "Familiarity with MLOps practices, including version control, CI/CD pipelines, and model monitoring.\n",
    "Excellent problem-solving skills and the ability to work collaboratively in a team environment.\n",
    "Knowledge of big data tools (e.g., Spark, Hadoop) and database technologies is a plus.\n",
    "Nice-to-Have:\n",
    "\n",
    "Experience in Natural Language Processing (NLP) and working with transformers and LLMs.\n",
    "Understanding of computer vision and related frameworks.\n",
    "Contributions to open-source ML projects or participation in hackathons.\n",
    "Perks and Benefits:\n",
    "\n",
    "Competitive salary and performance-based bonuses.\n",
    "Flexible working hours and remote work options.\n",
    "Access to training programs, conferences, and certifications for continuous learning.\n",
    "Comprehensive health and wellness benefits.\n",
    "A collaborative and inclusive work culture with opportunities for career growth.\"\"\"\n",
    "\n",
    "    if resume_file_path.endswith('.pdf'):\n",
    "        resume_text = extract_text_from_pdf(resume_file_path)  # pdf\n",
    "    elif resume_file_path.endswith('.docx'):\n",
    "        resume_text = extract_text_from_docx(resume_file_path)  # docx\n",
    "    else:\n",
    "        print(\"Unsupported file format.\")\n",
    "        return\n",
    "\n",
    "    preprocessed_resume_text = preprocess_text(resume_text)\n",
    "    preprocessed_jd_text = preprocess_text(jd_text)\n",
    "\n",
    "    similarity_score = calculate_similarity(' '.join(preprocessed_resume_text), ' '.join(preprocessed_jd_text))\n",
    "    print(\"The similarity score between the resume and job description is: \", similarity_score)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "dcad5474b6ca0f49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score between the resume and job description is:  0.32852134033908575\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f24074fe2db0279"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
